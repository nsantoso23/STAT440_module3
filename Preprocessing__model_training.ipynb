{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.layers import ZeroPadding2D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop potential randomness\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.abspath('C:\\\\Users\\\\LYC\\\\Desktop\\\\SFU\\\\Fall 2020 Courses\\\\STAT 440\\\\Module 3') \n",
    "data_dir = os.path.join(root_dir, 'tr') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = os.path.join(data_dir, 'img')\n",
    "# test = pd.read_csv(os.path.join(data_dir, 'Test.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path):\n",
    "    '''Put files into lists and return them as one list with all images \n",
    "     in the folder'''\n",
    "    image_files = sorted([os.path.join(path, 'img', file)\n",
    "                          for file in os.listdir(path + \"/img\")\n",
    "                          if file.endswith('.jpg')])\n",
    "    return image_files\n",
    "\n",
    "img = loadImages(data_dir)\n",
    "\n",
    "def load_test_Images(path):\n",
    "    '''Put files into lists and return them as one list with all images \n",
    "     in the folder'''\n",
    "    image_files = sorted([os.path.join(path, 'te', file)\n",
    "                          for file in os.listdir(path + \"/te\")\n",
    "                          if file.endswith('.jpg')])\n",
    "    return image_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadLbl(path):\n",
    "    '''Put files into lists and return them as one list with all images \n",
    "     in the folder'''\n",
    "    lbl_files = sorted([os.path.join(path, 'lbl', file)\n",
    "                          for file in os.listdir(path + \"/lbl\")\n",
    "                          if file.endswith('.txt')])\n",
    "    return lbl_files\n",
    "\n",
    "lbl = loadLbl(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for i in range(len(lbl)):\n",
    "    img2 = img[i][-11:]\n",
    "    label = open(lbl[i], \"r\").read()\n",
    "    label = label.replace(\"\\n\", \"\")\n",
    "    labels.append((img2, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(labels, columns=['name', 'label'])\n",
    "labels.to_csv('labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(root_dir, 'labels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for img_name in img:\n",
    "    pic = cv2.imread(img_name)\n",
    "    height = 56\n",
    "    width = 56\n",
    "    dim = (width, height)\n",
    "    res = cv2.resize(pic, dim, interpolation=cv2.INTER_LINEAR)\n",
    "    blur = cv2.GaussianBlur(res, (5, 5), 0)\n",
    "    a = image.img_to_array(blur)\n",
    "    a = a.astype('float32')\n",
    "    a /= 255.0\n",
    "    temp.append(a)\n",
    "    \n",
    "train_x = np.stack(temp)\n",
    "\n",
    "# train_x = train_x.reshape(-1, 784).astype('float32')\n",
    "\n",
    "# temp = []\n",
    "# for img_name in test.filename:\n",
    "#     image_path = os.path.join(data_dir, 'Train', 'Images', 'test', img_name)\n",
    "#     img = imread(image_path, flatten=True)\n",
    "#     img = img.astype('float32')\n",
    "#     temp.append(img)\n",
    "    \n",
    "# test_x = np.stack(temp)\n",
    "\n",
    "# test_x /= 255.0\n",
    "# test_x = test_x.reshape(-1, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_og_y = tf.keras.utils.to_categorical(train_data.label.values, num_classes=7, dtype=\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = int(train_x.shape[0]*0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x = train_x[:split_size], train_x[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y, val_y = train_og_y[:split_size], train_og_y[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884, 56, 56, 3)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.layers import ZeroPadding2D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.4.0.46-cp38-cp38-win_amd64.whl (33.5 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\lyc\\anaconda3\\lib\\site-packages (from opencv-python) (1.19.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.4.0.46\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "# model.add(Conv2D(32, kernel_size=(4, 4),activation='relu',strides = 2, input_shape=(56,56,3),padding='valid'))\n",
    "# model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',strides = 1))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',input_shape=(56,56,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides = 2))\n",
    "model.add(Conv2D(64, (3,3), activation='relu', strides = 2))\n",
    "model.add(Conv2D(32, (2,2), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(32, (2,2), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(1, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.Adamax(lr=0.0009), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "28/28 [==============================] - 21s 744ms/step - loss: 1.8211 - accuracy: 0.2262 - val_loss: 1.7693 - val_accuracy: 0.2401\n",
      "Epoch 2/60\n",
      "28/28 [==============================] - 23s 836ms/step - loss: 1.7691 - accuracy: 0.2285 - val_loss: 1.7627 - val_accuracy: 0.2401\n",
      "Epoch 3/60\n",
      "28/28 [==============================] - 21s 747ms/step - loss: 1.7694 - accuracy: 0.2081 - val_loss: 1.7780 - val_accuracy: 0.2375\n",
      "Epoch 4/60\n",
      "28/28 [==============================] - 21s 757ms/step - loss: 1.7559 - accuracy: 0.2432 - val_loss: 1.7432 - val_accuracy: 0.2507\n",
      "Epoch 5/60\n",
      "28/28 [==============================] - 21s 754ms/step - loss: 1.7575 - accuracy: 0.2070 - val_loss: 1.7287 - val_accuracy: 0.2375\n",
      "Epoch 6/60\n",
      "28/28 [==============================] - 21s 744ms/step - loss: 1.7397 - accuracy: 0.2217 - val_loss: 1.7037 - val_accuracy: 0.2823\n",
      "Epoch 7/60\n",
      "28/28 [==============================] - 21s 752ms/step - loss: 1.6706 - accuracy: 0.2851 - val_loss: 1.6324 - val_accuracy: 0.2929\n",
      "Epoch 8/60\n",
      "28/28 [==============================] - 21s 754ms/step - loss: 1.6505 - accuracy: 0.3167 - val_loss: 1.5989 - val_accuracy: 0.3456\n",
      "Epoch 9/60\n",
      "28/28 [==============================] - 22s 794ms/step - loss: 1.5667 - accuracy: 0.3439 - val_loss: 1.5739 - val_accuracy: 0.3325\n",
      "Epoch 10/60\n",
      "28/28 [==============================] - 23s 808ms/step - loss: 1.5320 - accuracy: 0.3699 - val_loss: 1.5162 - val_accuracy: 0.3905\n",
      "Epoch 11/60\n",
      "28/28 [==============================] - 21s 766ms/step - loss: 1.4931 - accuracy: 0.3903 - val_loss: 1.5037 - val_accuracy: 0.3773\n",
      "Epoch 12/60\n",
      "28/28 [==============================] - 22s 773ms/step - loss: 1.4429 - accuracy: 0.4129 - val_loss: 1.5520 - val_accuracy: 0.3668\n",
      "Epoch 13/60\n",
      "28/28 [==============================] - 28s 1s/step - loss: 1.4457 - accuracy: 0.4174 - val_loss: 1.4821 - val_accuracy: 0.4037\n",
      "Epoch 14/60\n",
      "28/28 [==============================] - 24s 871ms/step - loss: 1.4347 - accuracy: 0.4276 - val_loss: 1.4330 - val_accuracy: 0.4116\n",
      "Epoch 15/60\n",
      "28/28 [==============================] - 23s 813ms/step - loss: 1.3824 - accuracy: 0.4355 - val_loss: 1.4120 - val_accuracy: 0.4222\n",
      "Epoch 16/60\n",
      "28/28 [==============================] - 23s 832ms/step - loss: 1.3889 - accuracy: 0.4253 - val_loss: 1.4133 - val_accuracy: 0.4063\n",
      "Epoch 17/60\n",
      "28/28 [==============================] - 22s 780ms/step - loss: 1.3738 - accuracy: 0.4627 - val_loss: 1.3784 - val_accuracy: 0.4327\n",
      "Epoch 18/60\n",
      "28/28 [==============================] - 22s 769ms/step - loss: 1.3321 - accuracy: 0.4921 - val_loss: 1.3973 - val_accuracy: 0.4512\n",
      "Epoch 19/60\n",
      "28/28 [==============================] - 21s 764ms/step - loss: 1.3067 - accuracy: 0.5181 - val_loss: 1.3655 - val_accuracy: 0.4327\n",
      "Epoch 20/60\n",
      "28/28 [==============================] - 21s 764ms/step - loss: 1.3431 - accuracy: 0.4853 - val_loss: 1.4022 - val_accuracy: 0.4274\n",
      "Epoch 21/60\n",
      "28/28 [==============================] - 21s 763ms/step - loss: 1.2755 - accuracy: 0.5045 - val_loss: 1.3930 - val_accuracy: 0.4485\n",
      "Epoch 22/60\n",
      "28/28 [==============================] - 22s 778ms/step - loss: 1.2888 - accuracy: 0.4977 - val_loss: 1.3655 - val_accuracy: 0.4433\n",
      "Epoch 23/60\n",
      "28/28 [==============================] - 26s 939ms/step - loss: 1.2224 - accuracy: 0.5283 - val_loss: 1.3529 - val_accuracy: 0.4670\n",
      "Epoch 24/60\n",
      "28/28 [==============================] - 22s 773ms/step - loss: 1.2558 - accuracy: 0.5294 - val_loss: 1.3487 - val_accuracy: 0.4538\n",
      "Epoch 25/60\n",
      "28/28 [==============================] - 22s 785ms/step - loss: 1.2335 - accuracy: 0.5328 - val_loss: 1.3185 - val_accuracy: 0.4776\n",
      "Epoch 26/60\n",
      "28/28 [==============================] - 21s 761ms/step - loss: 1.2115 - accuracy: 0.5339 - val_loss: 1.4012 - val_accuracy: 0.4274\n",
      "Epoch 27/60\n",
      "28/28 [==============================] - 23s 821ms/step - loss: 1.1757 - accuracy: 0.5441 - val_loss: 1.2874 - val_accuracy: 0.4802\n",
      "Epoch 28/60\n",
      "28/28 [==============================] - 22s 771ms/step - loss: 1.1017 - accuracy: 0.5701 - val_loss: 1.2444 - val_accuracy: 0.5092\n",
      "Epoch 29/60\n",
      "28/28 [==============================] - 21s 757ms/step - loss: 1.0974 - accuracy: 0.5735 - val_loss: 1.2206 - val_accuracy: 0.5145\n",
      "Epoch 30/60\n",
      "28/28 [==============================] - 21s 767ms/step - loss: 1.0447 - accuracy: 0.6210 - val_loss: 1.2163 - val_accuracy: 0.5330\n",
      "Epoch 31/60\n",
      "28/28 [==============================] - 21s 753ms/step - loss: 1.0739 - accuracy: 0.6029 - val_loss: 1.2549 - val_accuracy: 0.5040\n",
      "Epoch 32/60\n",
      "28/28 [==============================] - 22s 769ms/step - loss: 1.0219 - accuracy: 0.6380 - val_loss: 1.2212 - val_accuracy: 0.5383\n",
      "Epoch 33/60\n",
      "28/28 [==============================] - 21s 762ms/step - loss: 1.0175 - accuracy: 0.6143 - val_loss: 1.2759 - val_accuracy: 0.4855\n",
      "Epoch 34/60\n",
      "28/28 [==============================] - 21s 763ms/step - loss: 1.0167 - accuracy: 0.6097 - val_loss: 1.2511 - val_accuracy: 0.5066\n",
      "Epoch 35/60\n",
      "28/28 [==============================] - 22s 769ms/step - loss: 1.0134 - accuracy: 0.6267 - val_loss: 1.1933 - val_accuracy: 0.5409\n",
      "Epoch 36/60\n",
      "28/28 [==============================] - 21s 756ms/step - loss: 0.9769 - accuracy: 0.6267 - val_loss: 1.1989 - val_accuracy: 0.5567\n",
      "Epoch 37/60\n",
      "28/28 [==============================] - 21s 761ms/step - loss: 0.9436 - accuracy: 0.6437 - val_loss: 1.1673 - val_accuracy: 0.5726\n",
      "Epoch 38/60\n",
      "28/28 [==============================] - 21s 766ms/step - loss: 0.9261 - accuracy: 0.6629 - val_loss: 1.2284 - val_accuracy: 0.5646\n",
      "Epoch 39/60\n",
      "28/28 [==============================] - 21s 759ms/step - loss: 0.8811 - accuracy: 0.6719 - val_loss: 1.1569 - val_accuracy: 0.5726\n",
      "Epoch 40/60\n",
      "28/28 [==============================] - 22s 774ms/step - loss: 0.8977 - accuracy: 0.6810 - val_loss: 1.2635 - val_accuracy: 0.5356\n",
      "Epoch 41/60\n",
      "28/28 [==============================] - 21s 755ms/step - loss: 0.9065 - accuracy: 0.6437 - val_loss: 1.1716 - val_accuracy: 0.5515\n",
      "Epoch 42/60\n",
      "28/28 [==============================] - 21s 759ms/step - loss: 0.8693 - accuracy: 0.6629 - val_loss: 1.2149 - val_accuracy: 0.5383\n",
      "Epoch 43/60\n",
      "28/28 [==============================] - 21s 766ms/step - loss: 0.8248 - accuracy: 0.7002 - val_loss: 1.1844 - val_accuracy: 0.5620\n",
      "Epoch 44/60\n",
      "28/28 [==============================] - 21s 761ms/step - loss: 0.8100 - accuracy: 0.7025 - val_loss: 1.1948 - val_accuracy: 0.5752\n",
      "Epoch 45/60\n",
      "28/28 [==============================] - 22s 772ms/step - loss: 0.7841 - accuracy: 0.7070 - val_loss: 1.2402 - val_accuracy: 0.5488\n",
      "Epoch 46/60\n",
      "28/28 [==============================] - 21s 760ms/step - loss: 0.8498 - accuracy: 0.6719 - val_loss: 1.2321 - val_accuracy: 0.5646\n",
      "Epoch 47/60\n",
      "28/28 [==============================] - 21s 757ms/step - loss: 0.8087 - accuracy: 0.6889 - val_loss: 1.2000 - val_accuracy: 0.5884\n",
      "Epoch 48/60\n",
      "28/28 [==============================] - 22s 781ms/step - loss: 0.7505 - accuracy: 0.7251 - val_loss: 1.2304 - val_accuracy: 0.5831\n",
      "Epoch 49/60\n",
      "28/28 [==============================] - 21s 764ms/step - loss: 0.7962 - accuracy: 0.7014 - val_loss: 1.1477 - val_accuracy: 0.5752\n",
      "Epoch 50/60\n",
      "28/28 [==============================] - 21s 767ms/step - loss: 0.7027 - accuracy: 0.7410 - val_loss: 1.2197 - val_accuracy: 0.5462\n",
      "Epoch 51/60\n",
      "28/28 [==============================] - 21s 764ms/step - loss: 0.6746 - accuracy: 0.7557 - val_loss: 1.1565 - val_accuracy: 0.5989\n",
      "Epoch 52/60\n",
      "28/28 [==============================] - 21s 759ms/step - loss: 0.6696 - accuracy: 0.7636 - val_loss: 1.2304 - val_accuracy: 0.5937\n",
      "Epoch 53/60\n",
      "28/28 [==============================] - 22s 770ms/step - loss: 0.7089 - accuracy: 0.7545 - val_loss: 1.1995 - val_accuracy: 0.5699\n",
      "Epoch 54/60\n",
      "28/28 [==============================] - 21s 761ms/step - loss: 0.6674 - accuracy: 0.7557 - val_loss: 1.2066 - val_accuracy: 0.5963\n",
      "Epoch 55/60\n",
      "28/28 [==============================] - 21s 754ms/step - loss: 0.6851 - accuracy: 0.7545 - val_loss: 1.1604 - val_accuracy: 0.5884\n",
      "Epoch 56/60\n",
      "28/28 [==============================] - 22s 769ms/step - loss: 0.6027 - accuracy: 0.7749 - val_loss: 1.2282 - val_accuracy: 0.5831\n",
      "Epoch 57/60\n",
      "28/28 [==============================] - 21s 760ms/step - loss: 0.6294 - accuracy: 0.7658 - val_loss: 1.2098 - val_accuracy: 0.5752\n",
      "Epoch 58/60\n",
      "28/28 [==============================] - 21s 764ms/step - loss: 0.6164 - accuracy: 0.7715 - val_loss: 1.3259 - val_accuracy: 0.5567\n",
      "Epoch 59/60\n",
      "28/28 [==============================] - 22s 775ms/step - loss: 0.5912 - accuracy: 0.7658 - val_loss: 1.2298 - val_accuracy: 0.5831\n",
      "Epoch 60/60\n",
      "28/28 [==============================] - 22s 790ms/step - loss: 0.5826 - accuracy: 0.7873 - val_loss: 1.2405 - val_accuracy: 0.5831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x83f929d0>"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=60, validation_data=(val_x, val_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-94-06b6ec2be1f6>:16: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "# prepare test data\n",
    "#load test set\n",
    "test = load_test_Images(root_dir)\n",
    "#read and store test image\n",
    "test_image = []\n",
    "for i in test:\n",
    "    pic = image.load_img(i, target_size=(227,227,1), grayscale=False)\n",
    "    a = image.img_to_array(pic)\n",
    "    a = a.astype('float32')\n",
    "    a /= 255.0\n",
    "    test_image.append(a)\n",
    "    \n",
    "test = np.stack(test_image)\n",
    "\n",
    "# making predictions\n",
    "prediction = model.predict_classes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 2, ..., 5, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import *\n",
    "idx = pd.Series(Int64Index(range(1264,2528)))\n",
    "prediction = pd.Series(prediction)\n",
    "\n",
    "data = concat([idx,prediction],axis = 1)\n",
    "data.columns = ['Id',\"Prediction\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating submission file\n",
    "data.to_csv('kaggle_submission.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
